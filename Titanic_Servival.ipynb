{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzxBbI648IWX",
        "outputId": "2b603b3b-492c-4a66-e998-f2e49893dc38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Embarked         2\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/train.csv')\n",
        "\n",
        "print(data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "평균 = data['Age'].mean()\n",
        "최빈값 = data['Embarked'].mode()[0]\n",
        "\n",
        "data['Age'].fillna(평균, inplace=True)\n",
        "data['Embarked'].fillna(최빈값, inplace=True)\n",
        "\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NH9-PZoO9J2b",
        "outputId": "fb21c06a-b2f7-41ad-ea27-95066bf5d847"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId    0\n",
            "Survived       0\n",
            "Pclass         0\n",
            "Name           0\n",
            "Sex            0\n",
            "Age            0\n",
            "SibSp          0\n",
            "Parch          0\n",
            "Ticket         0\n",
            "Fare           0\n",
            "Embarked       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-787fbf6e59b8>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Age'].fillna(평균, inplace=True)\n",
            "<ipython-input-25-787fbf6e59b8>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data['Embarked'].fillna(최빈값, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "정답 = data.pop('Survived')\n",
        "\n"
      ],
      "metadata": {
        "id": "F_xc0s0_9krc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ds = tf.data.Dataset.from_tensor_slices(((dict(data)), 정답))\n",
        "print(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfZw_K3v-O0o",
        "outputId": "05e1729f-1a24-4d11-e46f-1016bdedea30"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TensorSliceDataset element_spec=({'PassengerId': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Pclass': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Name': TensorSpec(shape=(), dtype=tf.string, name=None), 'Sex': TensorSpec(shape=(), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(), dtype=tf.float64, name=None), 'SibSp': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Parch': TensorSpec(shape=(), dtype=tf.int64, name=None), 'Ticket': TensorSpec(shape=(), dtype=tf.string, name=None), 'Fare': TensorSpec(shape=(), dtype=tf.float64, name=None), 'Embarked': TensorSpec(shape=(), dtype=tf.string, name=None)}, TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = []\n",
        "# 숫자\n",
        "feature_columns.append(tf.feature_column.numeric_column('Fare'))\n",
        "feature_columns.append(tf.feature_column.numeric_column('SibSp'))\n",
        "feature_columns.append(tf.feature_column.numeric_column('Parch'))\n",
        "\n",
        "#뭉뚱 카테고리\n",
        "Age= tf.feature_column.numeric_column('Age')\n",
        "Age_bucket = tf.feature_column.bucketized_column(Age, boundaries=[10, 20, 30, 40, 50, 60, 70, 80])\n",
        "feature_columns.append(Age_bucket)\n",
        "\n",
        "# 카테고리\n",
        "vocab = data['Sex'].unique()\n",
        "Sex = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Sex', vocab))\n",
        "feature_columns.append(Sex)\n",
        "\n",
        "vocab = data['Embarked'].unique()\n",
        "Embarked = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Embarked', vocab))\n",
        "feature_columns.append(Embarked)\n",
        "\n",
        "vocab = data['Pclass'].unique()\n",
        "Pclass = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Pclass', vocab))\n",
        "feature_columns.append(Pclass)\n"
      ],
      "metadata": {
        "id": "lzvYsbRf-ROS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "78c48ff7-1946-4cfa-bcde-6f0064ae956b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3918a55aea48>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Create a Keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m model = tf.keras.Sequential([\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDenseFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Apply feature columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.layers' has no attribute 'DenseFeatures'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#embedding (카테고리가 너무 많아)\n",
        "vocab = data['Ticket'].unique()\n",
        "Ticket = tf.feature_column.embedding_column(tf.feature_column.categorical_column_with_vocabulary_list('Ticket', vocab), dimension = 9)\n",
        "feature_columns.append(Ticket)\n"
      ],
      "metadata": {
        "id": "a_-to7-UA03g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "706599e9-567e-4e81-df61-d01cac6d81ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-c43a347055ef>:3: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peQoNkXWowxl",
        "outputId": "72552a19-d27a-4e8f-a9d3-afbb6a9d263d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Feature columns 정의\n",
        "feature_columns = []\n",
        "\n",
        "# 숫자형 feature columns 추가\n",
        "feature_columns.append(tf.feature_column.numeric_column('Fare'))\n",
        "feature_columns.append(tf.feature_column.numeric_column('SibSp'))\n",
        "feature_columns.append(tf.feature_column.numeric_column('Parch'))\n",
        "\n",
        "# Age에 대한 bucketized feature column 추가\n",
        "Age = tf.feature_column.numeric_column('Age')\n",
        "Age_bucket = tf.feature_column.bucketized_column(Age, boundaries=[10, 20, 30, 40, 50, 60, 70, 80])\n",
        "feature_columns.append(Age_bucket)\n",
        "\n",
        "# 범주형 feature columns 추가 (Sex, Embarked, Pclass)\n",
        "vocab = data['Sex'].unique()\n",
        "Sex = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Sex', vocab))\n",
        "feature_columns.append(Sex)\n",
        "\n",
        "vocab = data['Embarked'].unique()\n",
        "Embarked = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Embarked', vocab))\n",
        "feature_columns.append(Embarked)\n",
        "\n",
        "vocab = data['Pclass'].unique()\n",
        "Pclass = tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list('Pclass', vocab))\n",
        "feature_columns.append(Pclass)\n",
        "\n",
        "# Embedding feature column 추가 (Ticket)\n",
        "vocab = data['Ticket'].unique()\n",
        "Ticket = tf.feature_column.embedding_column(tf.feature_column.categorical_column_with_vocabulary_list('Ticket', vocab), dimension=9)\n",
        "feature_columns.append(Ticket)\n",
        "\n",
        "# Feature columns을 Dense 레이어로 변환하기 위한 방법\n",
        "# 모델 입력 정의\n",
        "input_layer = tf.keras.layers.Input(shape=(len(feature_columns),))\n",
        "\n",
        "# 각 feature_column에 대해 Dense 레이어로 변환\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(input_layer)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "# 출력층 정의 (이진 분류를 예시로 설정)\n",
        "output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# 모델 정의\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 구조 확인\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "cqUqHkMJBYQG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "50e9f9b4-abcb-46bc-b2a6-e13ea1e1b272"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m1,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │           \u001b[38;5;34m2,080\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,521\u001b[0m (45.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,521</span> (45.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,521\u001b[0m (45.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,521</span> (45.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 전체 데이터셋을 TensorFlow Dataset으로 변환\n",
        "ds = tf.data.Dataset.from_tensor_slices((dict(data), 정답))\n",
        "\n",
        "# 데이터셋을 훈련 데이터와 검증 데이터로 나누기\n",
        "train_data, val_data = train_test_split(list(ds), test_size=0.2, random_state=42)\n",
        "\n",
        "# tf.data.Dataset으로 변환\n",
        "train_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: iter(train_data),\n",
        "    output_signature=(\n",
        "        {\n",
        "            'PassengerId': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Pclass': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Name': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            'Sex': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            'Age': tf.TensorSpec(shape=(), dtype=tf.float64),\n",
        "            'SibSp': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Parch': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Ticket': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            'Fare': tf.TensorSpec(shape=(), dtype=tf.float64),\n",
        "            'Embarked': tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "        },\n",
        "        tf.TensorSpec(shape=(), dtype=tf.float32)  # 정답 데이터 (Survived)\n",
        "    )\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: iter(val_data),\n",
        "    output_signature=(\n",
        "        {\n",
        "            'PassengerId': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Pclass': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Name': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            'Sex': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            'Age': tf.TensorSpec(shape=(), dtype=tf.float64),\n",
        "            'SibSp': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Parch': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
        "            'Ticket': tf.TensorSpec(shape=(), dtype=tf.string),\n",
        "            'Fare': tf.TensorSpec(shape=(), dtype=tf.float64),\n",
        "            'Embarked': tf.TensorSpec(shape=(), dtype=tf.string)\n",
        "        },\n",
        "        tf.TensorSpec(shape=(), dtype=tf.float32)  # 정답 데이터 (Survived)\n",
        "    )\n",
        ")\n",
        "\n",
        "# 데이터를 float32로 변환하고, 배치 처리\n",
        "train_dataset = train_dataset.map(lambda features, label: (features, tf.cast(label, tf.float32)))\n",
        "val_dataset = val_dataset.map(lambda features, label: (features, tf.cast(label, tf.float32)))\n",
        "\n",
        "train_dataset = train_dataset.batch(32)\n",
        "val_dataset = val_dataset.batch(32)\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(train_dataset, epochs=10, validation_data=val_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "JsMi7mQRnsui",
        "outputId": "451d45be-ab64-45c2-82e6-45e427d41e00"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Missing data for input \"input_layer_5\". You passed a data dictionary with keys ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']. Expected the following keys: ['input_layer_5']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-bf0422948fbe>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# 모델 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    150\u001b[0m                         \u001b[0;34mf'Missing data for input \"{name}\". '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                         \u001b[0;34m\"You passed a data dictionary with keys \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Missing data for input \"input_layer_5\". You passed a data dictionary with keys ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked']. Expected the following keys: ['input_layer_5']"
          ]
        }
      ]
    }
  ]
}